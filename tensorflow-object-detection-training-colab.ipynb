{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tensorflow-object-detection-training-colab.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/Tony607/object_detection_demo/blob/master/tensorflow_object_detection_training_colab.ipynb","timestamp":1565616133016}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uQCnYPVDrsgx","colab_type":"text"},"source":["# [How to train an object detection model easy for free](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) | DLology Blog"]},{"cell_type":"markdown","metadata":{"id":"yhzxsJb3dpWq","colab_type":"text"},"source":["## Configs and Hyperparameters\n","\n","Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."]},{"cell_type":"code","metadata":{"id":"patPTuPHAhwL","colab_type":"code","outputId":"35f0b164-e7ca-41d2-91ac-b9a31c77bb53","executionInfo":{"status":"ok","timestamp":1565622984305,"user_tz":-330,"elapsed":85668,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":189}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uuGECSTZE8bi","colab_type":"code","colab":{}},"source":["# If you forked the repository, you can replace the link.\n","repo_url = 'https://github.com/SiddharthMehtaRajendra/object_detection_demo'\n","\n","# Number of training steps.\n","num_steps = 1000  # 200000\n","\n","# Number of evaluation steps.\n","num_eval_steps = 50\n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    }\n","}\n","\n","# Pick the model you want to use\n","# Select a model in `MODELS_CONFIG`.\n","selected_model = 'ssd_mobilenet_v2'\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"su_wOrpSA4v_","colab_type":"code","colab":{}},"source":["project_path = \"/content/drive/My Drive/Colab Notebooks/Great Lakes Capstone Project/Tensorflow/\"\n","obj_detection_path = \"/content/drive/My Drive/Colab Notebooks/Great Lakes Capstone Project/Tensorflow/models/research/object_detection/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KdMdmgkBMq6","colab_type":"code","outputId":"87f811ab-d6c8-4070-864f-6584734cdd7e","executionInfo":{"status":"ok","timestamp":1565617604311,"user_tz":-330,"elapsed":1015,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pwd"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"w4V-XE6kbkc1","colab_type":"text"},"source":["## Clone the `object_detection_demo` repository or your fork."]},{"cell_type":"code","metadata":{"id":"dxc3DmvLQF3z","colab_type":"code","outputId":"e0165b3c-09de-4be1-fb97-0b30490513d4","executionInfo":{"status":"ok","timestamp":1565623187873,"user_tz":-330,"elapsed":6174,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":216}},"source":["import os\n","\n","%cd /content\n","\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","\n","!git clone {repo_url}\n","%cd {repo_dir_path}\n","!git pull"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'object_detection_demo'...\n","remote: Enumerating objects: 214, done.\u001b[K\n","remote: Counting objects: 100% (214/214), done.\u001b[K\n","remote: Compressing objects: 100% (114/114), done.\u001b[K\n","remote: Total 414 (delta 101), reused 212 (delta 100), pack-reused 200\u001b[K\n","Receiving objects: 100% (414/414), 12.90 MiB | 31.16 MiB/s, done.\n","Resolving deltas: 100% (192/192), done.\n","/content/object_detection_demo\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bI8__uNS8-ns","colab_type":"text"},"source":["## Install required packages"]},{"cell_type":"code","metadata":{"id":"ecpHEnka8Kix","colab_type":"code","outputId":"1359558e-25c8-4b23-ba69-124c10c3ab02","executionInfo":{"status":"ok","timestamp":1565623282942,"user_tz":-330,"elapsed":49310,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","\n","!pip install -q pycocotools\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 131289 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Setting up python-pil:amd64 (5.1.0-1) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","/content/models/research\n","WARNING: Logging before flag parsing goes to stderr.\n","W0812 15:21:20.688999 140400975198080 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","W0812 15:21:21.037399 140400975198080 deprecation_wrapper.py:119] From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0812 15:21:21.088013 140400975198080 deprecation_wrapper.py:119] From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","Running tests under Python 3.6.8: /usr/bin/python3\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n","[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n","[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n","[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n","[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTest.test_session\n","[  SKIPPED ] ModelBuilderTest.test_session\n","[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n","[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n","[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n","[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 16 tests in 0.140s\n","\n","OK (skipped=1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u-k7uGThXlny","colab_type":"text"},"source":["## Prepare `tfrecord` files\n","\n","Use the following scripts to generate the `tfrecord` files.\n","```bash\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","# Convert test folder annotation xml files to a single csv.\n","python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n","\n","# Generate `train.record`\n","python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# Generate `test.record`\n","python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n","```"]},{"cell_type":"code","metadata":{"id":"ezGDABRXXhPP","colab_type":"code","outputId":"23117c97-735f-4177-8ce9-f3274e20635e","executionInfo":{"status":"ok","timestamp":1565623526824,"user_tz":-330,"elapsed":13524,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":446}},"source":["%cd {repo_dir_path}\n","\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n","\n","# Convert test folder annotation xml files to a single csv.\n","!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n","\n","# Generate `train.record`\n","!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n","\n","# Generate `test.record`\n","!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/object_detection_demo\n","Successfully converted xml to csv.\n","Generate `data/annotations/label_map.pbtxt`\n","Successfully converted xml to csv.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0812 15:25:20.977336 139968475461504 deprecation_wrapper.py:119] From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","W0812 15:25:20.977859 139968475461504 deprecation_wrapper.py:119] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0812 15:25:20.987542 139968475461504 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/object_detection_demo/data/annotations/train.record\n","WARNING: Logging before flag parsing goes to stderr.\n","W0812 15:25:24.817950 140659951253376 deprecation_wrapper.py:119] From generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","W0812 15:25:24.818538 140659951253376 deprecation_wrapper.py:119] From generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0812 15:25:24.828921 140659951253376 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/object_detection_demo/data/annotations/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tgd-fzAIkZlV","colab_type":"code","colab":{}},"source":["test_record_fname = '/content/object_detection_demo/data/annotations/test.record'\n","train_record_fname = '/content/object_detection_demo/data/annotations/train.record'\n","label_map_pbtxt_fname = '/content/object_detection_demo/data/annotations/label_map.pbtxt'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCNYAaC7w6N8","colab_type":"text"},"source":["## Download base model"]},{"cell_type":"code","metadata":{"id":"orDCj6ihgUMR","colab_type":"code","outputId":"da3a31e4-d455-4308-ef93-ed66a3a23325","executionInfo":{"status":"ok","timestamp":1565623943496,"user_tz":-330,"elapsed":5385,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pGhvAObeiIix","colab_type":"code","outputId":"eff0f385-d4af-455d-c798-f43a4a851e82","executionInfo":{"status":"ok","timestamp":1565623951169,"user_tz":-330,"elapsed":5741,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/models/research/pretrained_model\n","total 135M\n","drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n","drwxr-xr-x 71 root   root  4.0K Aug 12 15:32 ..\n","-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n","-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n","-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n","-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n","-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n","-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n","drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UHnxlfRznPP3","colab_type":"code","outputId":"9bc4e703-568d-4335-a1b7-0f8568c4a98a","executionInfo":{"status":"ok","timestamp":1565623953020,"user_tz":-330,"elapsed":611,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"MvwtHlLOeRJD","colab_type":"text"},"source":["## Configuring a Training Pipeline"]},{"cell_type":"code","metadata":{"id":"dIhw7IdpLuiU","colab_type":"code","colab":{}},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fG1nCNpUXcRU","colab_type":"code","colab":{}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjtCbLF2i0wI","colab_type":"code","colab":{}},"source":["import re\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GH0MEEanocn6","colab_type":"code","outputId":"25ee1387-5e8d-49e4-c70f-e81332a16dab","executionInfo":{"status":"ok","timestamp":1565623974093,"user_tz":-330,"elapsed":2818,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!cat {pipeline_fname}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  ssd {\n","    num_classes: 2\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.95\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.3333\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.8\n","        kernel_size: 1\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.00004\n","            }\n","          }\n","          initializer {\n","            truncated_normal_initializer {\n","              stddev: 0.03\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            train: true,\n","            scale: true,\n","            center: true,\n","            decay: 0.9997,\n","            epsilon: 0.001,\n","          }\n","        }\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_mobilenet_v2'\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.00004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          train: true,\n","          scale: true,\n","          center: true,\n","          decay: 0.9997,\n","          epsilon: 0.001,\n","        }\n","      }\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid {\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      hard_example_miner {\n","        num_hard_examples: 3000\n","        iou_threshold: 0.99\n","        loss_type: CLASSIFICATION\n","        max_negatives_per_positive: 3\n","        min_negatives_per_image: 3\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 12\n","  optimizer {\n","    rms_prop_optimizer: {\n","      learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.004\n","          decay_steps: 800720\n","          decay_factor: 0.95\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","      decay: 0.9\n","      epsilon: 1.0\n","    }\n","  }\n","  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n","  fine_tune_checkpoint_type:  \"detection\"\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 1000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/object_detection_demo/data/annotations/train.record\"\n","  }\n","  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 8000\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/object_detection_demo/data/annotations/test.record\"\n","  }\n","  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f11w0uO3jFCB","colab_type":"code","colab":{}},"source":["model_dir = 'training/'\n","# Optionally remove content in output model directory to fresh start.\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23TECXvNezIF","colab_type":"text"},"source":["## Run Tensorboard(Optional)"]},{"cell_type":"code","metadata":{"id":"0H2PZs-mSCmO","colab_type":"code","outputId":"50ba3f84-c9e2-4368-83dd-ac1be41a706e","executionInfo":{"status":"ok","timestamp":1565624014351,"user_tz":-330,"elapsed":5356,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-08-12 15:33:30--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 54.152.127.232, 52.207.111.186, 3.214.169.236, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|54.152.127.232|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13607069 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  12%[=>                  ]   1.66M  8.24MB/s               \rngrok-stable-linux- 100%[===================>]  12.98M  40.3MB/s    in 0.3s    \n","\n","2019-08-12 15:33:30 (40.3 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13607069/13607069]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G8o6r1o5SC5M","colab_type":"code","colab":{}},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ge1OX7gcSC7S","colab_type":"code","colab":{}},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5GSGxZNh8rp","colab_type":"text"},"source":["### Get Tensorboard link"]},{"cell_type":"code","metadata":{"id":"rjhPT9iPSJ6T","colab_type":"code","outputId":"1331e318-4203-4c31-8abb-8ab7f08a94ee","executionInfo":{"status":"ok","timestamp":1565624023812,"user_tz":-330,"elapsed":3705,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["https://b45c5147.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JDddx2rPfex9","colab_type":"text"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"nC7_syR1SJ9F","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CjDHjhKQofT5","colab_type":"code","outputId":"71f2c01d-27f6-4f89-9ac1-97ed7ccafdaa","executionInfo":{"status":"ok","timestamp":1565624556006,"user_tz":-330,"elapsed":515805,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0812 15:34:04.507450 140646502270848 lazy_loader.py:50] \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","W0812 15:34:04.545355 140646502270848 deprecation_wrapper.py:119] From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0812 15:34:04.556015 140646502270848 deprecation_wrapper.py:119] From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","W0812 15:34:04.602798 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","W0812 15:34:04.603684 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0812 15:34:04.607554 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:616: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","W0812 15:34:04.607680 140646502270848 model_lib.py:617] Forced number of epochs for all eval validations to be 1.\n","W0812 15:34:04.607796 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","I0812 15:34:04.607883 140646502270848 config_util.py:488] Maybe overwriting train_steps: 1000\n","I0812 15:34:04.607961 140646502270848 config_util.py:488] Maybe overwriting use_bfloat16: False\n","I0812 15:34:04.608032 140646502270848 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0812 15:34:04.608104 140646502270848 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n","I0812 15:34:04.608178 140646502270848 config_util.py:488] Maybe overwriting load_pretrained: True\n","I0812 15:34:04.608239 140646502270848 config_util.py:498] Ignoring config override key: load_pretrained\n","W0812 15:34:04.608342 140646502270848 model_lib.py:633] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","I0812 15:34:04.608424 140646502270848 model_lib.py:668] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","I0812 15:34:04.608889 140646502270848 estimator.py:209] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fea82876dd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","W0812 15:34:04.609102 140646502270848 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fea82300ea0>) includes params argument, but params are not passed to Estimator.\n","I0812 15:34:04.610085 140646502270848 estimator_training.py:186] Not using Distribute Coordinator.\n","I0812 15:34:04.610298 140646502270848 training.py:612] Running training and evaluation locally (non-distributed).\n","I0812 15:34:04.610531 140646502270848 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","W0812 15:34:04.616932 140646502270848 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0812 15:34:04.629645 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0812 15:34:04.629887 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","W0812 15:34:04.643372 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W0812 15:34:04.649472 140646502270848 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n","W0812 15:34:04.655377 140646502270848 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0812 15:34:04.655502 140646502270848 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0812 15:34:04.681773 140646502270848 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0812 15:34:04.871001 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/ops.py:491: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","W0812 15:34:04.875113 140646502270848 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0812 15:34:04.922549 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/preprocessor.py:626: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0812 15:34:04.979820 140646502270848 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:196: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0812 15:34:05.925700 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/preprocessor.py:2660: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0812 15:34:06.488552 140646502270848 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","I0812 15:34:06.502528 140646502270848 estimator.py:1145] Calling model_fn.\n","I0812 15:34:10.397311 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:34:10.434690 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:34:10.469377 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:34:10.504430 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:34:10.539711 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:34:10.574965 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","W0812 15:34:10.613762 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","W0812 15:34:10.618688 140646502270848 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n","W0812 15:34:10.618929 140646502270848 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n","W0812 15:34:10.619086 140646502270848 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n","W0812 15:34:10.619226 140646502270848 variables_helper.py:154] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n","W0812 15:34:10.619433 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:345: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n","\n","W0812 15:34:14.140484 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1089: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","W0812 15:34:14.147082 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","W0812 15:34:14.148495 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","W0812 15:34:14.505524 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:372: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0812 15:34:14.505925 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n","\n","W0812 15:34:14.515766 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n","\n","W0812 15:34:16.739836 140646502270848 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","I0812 15:34:24.162255 140646502270848 estimator.py:1147] Done calling model_fn.\n","I0812 15:34:24.163848 140646502270848 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","I0812 15:34:28.360727 140646502270848 monitored_session.py:240] Graph was finalized.\n","2019-08-12 15:34:28.366875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-08-12 15:34:28.367102: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x326f100 executing computations on platform Host. Devices:\n","2019-08-12 15:34:28.367132: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n","2019-08-12 15:34:28.369595: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n","2019-08-12 15:34:28.497351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:34:28.497910: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x106b4000 executing computations on platform CUDA. Devices:\n","2019-08-12 15:34:28.497955: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2019-08-12 15:34:28.498272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:34:28.498640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2019-08-12 15:34:28.499010: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-08-12 15:34:28.500320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2019-08-12 15:34:28.501525: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2019-08-12 15:34:28.501854: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2019-08-12 15:34:28.503249: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2019-08-12 15:34:28.504286: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2019-08-12 15:34:28.507415: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2019-08-12 15:34:28.507564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:34:28.508028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:34:28.508361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2019-08-12 15:34:28.508419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-08-12 15:34:28.509384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-08-12 15:34:28.509410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2019-08-12 15:34:28.509421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2019-08-12 15:34:28.509716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:34:28.510124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:34:28.510475: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2019-08-12 15:34:28.510524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12179 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","2019-08-12 15:34:33.589724: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n","I0812 15:34:33.715640 140646502270848 session_manager.py:500] Running local_init_op.\n","I0812 15:34:34.004615 140646502270848 session_manager.py:502] Done running local_init_op.\n","I0812 15:34:44.709238 140646502270848 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n","2019-08-12 15:34:53.310913: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","I0812 15:34:56.682620 140646502270848 basic_session_run_hooks.py:262] loss = 17.34622, step = 0\n","I0812 15:35:44.159919 140646502270848 basic_session_run_hooks.py:692] global_step/sec: 2.10624\n","I0812 15:35:44.161141 140646502270848 basic_session_run_hooks.py:260] loss = 6.7014055, step = 100 (47.479 sec)\n","I0812 15:36:28.021279 140646502270848 basic_session_run_hooks.py:692] global_step/sec: 2.27991\n","I0812 15:36:28.022802 140646502270848 basic_session_run_hooks.py:260] loss = 5.143351, step = 200 (43.862 sec)\n","I0812 15:37:11.680776 140646502270848 basic_session_run_hooks.py:692] global_step/sec: 2.29045\n","I0812 15:37:11.682238 140646502270848 basic_session_run_hooks.py:260] loss = 4.990637, step = 300 (43.659 sec)\n","I0812 15:37:55.313893 140646502270848 basic_session_run_hooks.py:692] global_step/sec: 2.29184\n","I0812 15:37:55.314997 140646502270848 basic_session_run_hooks.py:260] loss = 5.4792867, step = 400 (43.633 sec)\n","I0812 15:38:38.503684 140646502270848 basic_session_run_hooks.py:692] global_step/sec: 2.31536\n","I0812 15:38:38.505097 140646502270848 basic_session_run_hooks.py:260] loss = 5.4534287, step = 500 (43.190 sec)\n","I0812 15:39:21.550295 140646502270848 basic_session_run_hooks.py:692] global_step/sec: 2.32306\n","I0812 15:39:21.551562 140646502270848 basic_session_run_hooks.py:260] loss = 3.649056, step = 600 (43.046 sec)\n","I0812 15:40:04.512216 140646502270848 basic_session_run_hooks.py:692] global_step/sec: 2.32764\n","I0812 15:40:04.513656 140646502270848 basic_session_run_hooks.py:260] loss = 4.4070005, step = 700 (42.962 sec)\n","I0812 15:40:47.201435 140646502270848 basic_session_run_hooks.py:692] global_step/sec: 2.34251\n","I0812 15:40:47.203088 140646502270848 basic_session_run_hooks.py:260] loss = 3.642115, step = 800 (42.689 sec)\n","I0812 15:41:30.389968 140646502270848 basic_session_run_hooks.py:692] global_step/sec: 2.31543\n","I0812 15:41:30.391121 140646502270848 basic_session_run_hooks.py:260] loss = 3.0429542, step = 900 (43.188 sec)\n","I0812 15:42:12.576139 140646502270848 basic_session_run_hooks.py:606] Saving checkpoints for 1000 into training/model.ckpt.\n","I0812 15:42:15.327733 140646502270848 estimator.py:1145] Calling model_fn.\n","I0812 15:42:17.918002 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:42:17.955024 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:42:17.990029 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:42:18.025993 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:42:18.061583 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:42:18.097787 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","W0812 15:42:18.938599 140646502270848 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0812 15:42:19.600323 140646502270848 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0812 15:42:19.777600 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/visualization_utils.py:1010: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","W0812 15:42:19.877422 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:472: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","I0812 15:42:20.227651 140646502270848 estimator.py:1147] Done calling model_fn.\n","I0812 15:42:20.247178 140646502270848 evaluation.py:255] Starting evaluation at 2019-08-12T15:42:20Z\n","I0812 15:42:20.740305 140646502270848 monitored_session.py:240] Graph was finalized.\n","2019-08-12 15:42:20.741800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:42:20.742179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2019-08-12 15:42:20.742278: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-08-12 15:42:20.742302: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2019-08-12 15:42:20.742329: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2019-08-12 15:42:20.742351: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2019-08-12 15:42:20.742372: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2019-08-12 15:42:20.742392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2019-08-12 15:42:20.742415: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2019-08-12 15:42:20.742550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:42:20.742949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:42:20.743290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2019-08-12 15:42:20.743337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-08-12 15:42:20.743353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2019-08-12 15:42:20.743364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2019-08-12 15:42:20.743646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:42:20.744036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:42:20.744346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12179 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","W0812 15:42:20.744509 140646502270848 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","I0812 15:42:20.745784 140646502270848 saver.py:1280] Restoring parameters from training/model.ckpt-1000\n","I0812 15:42:21.612172 140646502270848 session_manager.py:500] Running local_init_op.\n","I0812 15:42:21.724352 140646502270848 session_manager.py:502] Done running local_init_op.\n","I0812 15:42:25.390717 140644721518336 coco_evaluation.py:205] Performing evaluation on 34 images.\n","creating index...\n","index created!\n","I0812 15:42:25.393469 140644721518336 coco_tools.py:115] Loading and preparing annotation results...\n","I0812 15:42:25.396487 140644721518336 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.30s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.078\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.031\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.047\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.082\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","I0812 15:42:25.961256 140646502270848 evaluation.py:275] Finished evaluation at 2019-08-12-15:42:25\n","I0812 15:42:25.961568 140646502270848 estimator.py:2039] Saving dict for global step 1000: DetectionBoxes_Precision/mAP = 0.027583908, DetectionBoxes_Precision/mAP (large) = -1.0, DetectionBoxes_Precision/mAP (medium) = 0.04654966, DetectionBoxes_Precision/mAP (small) = 0.03091261, DetectionBoxes_Precision/mAP@.50IOU = 0.07785538, DetectionBoxes_Precision/mAP@.75IOU = 0.0019457828, DetectionBoxes_Recall/AR@1 = 0.038709678, DetectionBoxes_Recall/AR@10 = 0.08225807, DetectionBoxes_Recall/AR@100 = 0.102304146, DetectionBoxes_Recall/AR@100 (large) = -1.0, DetectionBoxes_Recall/AR@100 (medium) = 0.17083333, DetectionBoxes_Recall/AR@100 (small) = 0.05263158, Loss/classification_loss = 9.929283, Loss/localization_loss = 3.2322254, Loss/regularization_loss = 0.25230694, Loss/total_loss = 13.413817, global_step = 1000, learning_rate = 0.004, loss = 13.413817\n","I0812 15:42:26.829943 140646502270848 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1000: training/model.ckpt-1000\n","I0812 15:42:26.830809 140646502270848 exporter.py:410] Performing the final export in the end of training.\n","I0812 15:42:27.043100 140646502270848 estimator.py:1145] Calling model_fn.\n","I0812 15:42:29.659557 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:42:29.697047 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:42:29.733142 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:42:29.768162 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:42:29.805393 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:42:29.840220 140646502270848 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","W0812 15:42:30.329584 140646502270848 deprecation_wrapper.py:119] From /content/models/research/object_detection/model_lib.py:418: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","I0812 15:42:31.282242 140646502270848 estimator.py:1147] Done calling model_fn.\n","W0812 15:42:31.282545 140646502270848 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","I0812 15:42:31.283240 140646502270848 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","I0812 15:42:31.283353 140646502270848 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","I0812 15:42:31.283427 140646502270848 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0812 15:42:31.283486 140646502270848 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","I0812 15:42:31.283542 140646502270848 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","2019-08-12 15:42:31.284184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:42:31.284583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2019-08-12 15:42:31.284675: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-08-12 15:42:31.284710: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2019-08-12 15:42:31.284734: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2019-08-12 15:42:31.284757: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2019-08-12 15:42:31.284779: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2019-08-12 15:42:31.284799: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2019-08-12 15:42:31.284821: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2019-08-12 15:42:31.284967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:42:31.285340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:42:31.285600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2019-08-12 15:42:31.285643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-08-12 15:42:31.285656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2019-08-12 15:42:31.285666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2019-08-12 15:42:31.285913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:42:31.286258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:42:31.286535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12179 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","I0812 15:42:31.289411 140646502270848 saver.py:1280] Restoring parameters from training/model.ckpt-1000\n","I0812 15:42:31.769093 140646502270848 builder_impl.py:661] Assets added to graph.\n","I0812 15:42:31.769326 140646502270848 builder_impl.py:456] No assets to write.\n","I0812 15:42:32.619696 140646502270848 builder_impl.py:421] SavedModel written to: training/export/Servo/temp-b'1565624546'/saved_model.pb\n","I0812 15:42:33.034857 140646502270848 estimator.py:368] Loss for final step: 4.358218.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KP-tUdtnRybs","colab_type":"code","outputId":"339c183d-bff4-4885-af10-fa980257bda6","executionInfo":{"status":"ok","timestamp":1565624656460,"user_tz":-330,"elapsed":2679,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["!ls {model_dir}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["checkpoint\n","eval_0\n","events.out.tfevents.1565624065.101e894c698a\n","export\n","graph.pbtxt\n","model.ckpt-0.data-00000-of-00001\n","model.ckpt-0.index\n","model.ckpt-0.meta\n","model.ckpt-1000.data-00000-of-00001\n","model.ckpt-1000.index\n","model.ckpt-1000.meta\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_1Nrqw3nqnCh","colab_type":"code","colab":{}},"source":["# Legacy way of training(also works).\n","# !python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OmSESMetj1sa","colab_type":"text"},"source":["## Exporting a Trained Inference Graph\n","Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"]},{"cell_type":"code","metadata":{"id":"DHoP90pUyKSq","colab_type":"code","outputId":"8b929d32-5749-4657-ee20-8632bf8314e2","executionInfo":{"status":"ok","timestamp":1565624679395,"user_tz":-330,"elapsed":17308,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import re\n","import numpy as np\n","\n","output_directory = './fine_tuned_model'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)\n","!python /content/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --output_directory={output_directory} \\\n","    --trained_checkpoint_prefix={last_model_path}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["training/model.ckpt-1000\n","WARNING: Logging before flag parsing goes to stderr.\n","W0812 15:44:26.322377 139670263756672 deprecation_wrapper.py:119] From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0812 15:44:26.334233 139670263756672 deprecation_wrapper.py:119] From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","W0812 15:44:26.345688 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","W0812 15:44:26.346350 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0812 15:44:26.352802 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:381: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0812 15:44:26.353136 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:113: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0812 15:44:26.390548 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/preprocessor.py:2660: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0812 15:44:26.421742 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:575: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0812 15:44:29.455481 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/anchor_generator.py:154: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0812 15:44:29.469581 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","I0812 15:44:29.469751 139670263756672 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:44:29.519656 139670263756672 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:44:29.572105 139670263756672 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:44:29.618551 139670263756672 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:44:29.663401 139670263756672 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","I0812 15:44:29.708199 139670263756672 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","W0812 15:44:30.013024 139670263756672 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:567: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0812 15:44:30.537902 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:260: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0812 15:44:30.538158 139670263756672 deprecation.py:323] From /content/models/research/object_detection/exporter.py:362: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0812 15:44:30.542111 139670263756672 deprecation.py:323] From /content/models/research/object_detection/exporter.py:518: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0812 15:44:30.543199 139670263756672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","149 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.59m params)\n","  BoxPredictor_0 (--/12.12k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/5.19k params)\n","      BoxPredictor_0/ClassPredictor/biases (9, 9/9 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x9, 5.18k/5.18k params)\n","  BoxPredictor_1 (--/53.80k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/23.06k params)\n","      BoxPredictor_1/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x18, 23.04k/23.04k params)\n","  BoxPredictor_2 (--/21.55k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/9.23k params)\n","      BoxPredictor_2/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x18, 9.22k/9.22k params)\n","  BoxPredictor_3 (--/10.79k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/4.63k params)\n","      BoxPredictor_3/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n","  BoxPredictor_4 (--/10.79k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/4.63k params)\n","      BoxPredictor_4/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n","  BoxPredictor_5 (--/5.42k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/2.32k params)\n","      BoxPredictor_5/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x18, 2.30k/2.30k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","149 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/17.63k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/add_2 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/add_5 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/add_8 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/add_11 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/add_14 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/add_1 (19/19 flops)\n","  MultipleGridAnchorGenerator/add (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/add_17 (12/12 flops)\n","  MultipleGridAnchorGenerator/add_3 (10/10 flops)\n","  MultipleGridAnchorGenerator/add_4 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/add_6 (5/5 flops)\n","  MultipleGridAnchorGenerator/add_7 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/add_10 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/add_9 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/add_12 (2/2 flops)\n","  MultipleGridAnchorGenerator/add_13 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Preprocessor/map/while/add_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Preprocessor/map/while/add (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_23 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_18 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_19 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_20 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_21 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_22 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/add_15 (1/1 flops)\n","  MultipleGridAnchorGenerator/add_16 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","\n","======================End of Report==========================\n","W0812 15:44:31.722718 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:411: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","2019-08-12 15:44:32.782562: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n","2019-08-12 15:44:32.788317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:32.788706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2019-08-12 15:44:32.788968: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-08-12 15:44:32.790836: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2019-08-12 15:44:32.792071: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2019-08-12 15:44:32.792433: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2019-08-12 15:44:32.793986: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2019-08-12 15:44:32.795136: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2019-08-12 15:44:32.798548: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2019-08-12 15:44:32.798751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:32.799194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:32.799548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2019-08-12 15:44:32.805636: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-08-12 15:44:32.805847: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1829800 executing computations on platform Host. Devices:\n","2019-08-12 15:44:32.805894: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n","2019-08-12 15:44:32.945274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:32.945808: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1829640 executing computations on platform CUDA. Devices:\n","2019-08-12 15:44:32.945839: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2019-08-12 15:44:32.946143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:32.946506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2019-08-12 15:44:32.946573: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-08-12 15:44:32.946595: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2019-08-12 15:44:32.946616: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2019-08-12 15:44:32.946638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2019-08-12 15:44:32.946658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2019-08-12 15:44:32.946677: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2019-08-12 15:44:32.946698: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2019-08-12 15:44:32.946788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:32.947235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:32.947570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2019-08-12 15:44:32.947640: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-08-12 15:44:32.948712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-08-12 15:44:32.948742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2019-08-12 15:44:32.948756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2019-08-12 15:44:32.949109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:32.949536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:32.949897: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2019-08-12 15:44:32.949949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12179 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","W0812 15:44:32.950682 139670263756672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","I0812 15:44:32.952002 139670263756672 saver.py:1280] Restoring parameters from training/model.ckpt-1000\n","2019-08-12 15:44:35.485378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:35.485826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2019-08-12 15:44:35.485936: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-08-12 15:44:35.485963: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2019-08-12 15:44:35.485985: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2019-08-12 15:44:35.486005: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2019-08-12 15:44:35.486024: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2019-08-12 15:44:35.486044: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2019-08-12 15:44:35.486065: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2019-08-12 15:44:35.486174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:35.486604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:35.486990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2019-08-12 15:44:35.487035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-08-12 15:44:35.487050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2019-08-12 15:44:35.487061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2019-08-12 15:44:35.487339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:35.488135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:35.488473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12179 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","I0812 15:44:35.489845 139670263756672 saver.py:1280] Restoring parameters from training/model.ckpt-1000\n","W0812 15:44:36.108768 139670263756672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0812 15:44:36.109042 139670263756672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","I0812 15:44:36.421625 139670263756672 graph_util_impl.py:311] Froze 324 variables.\n","I0812 15:44:36.504684 139670263756672 graph_util_impl.py:364] Converted 324 variables to const ops.\n","2019-08-12 15:44:36.652596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:36.653085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2019-08-12 15:44:36.653211: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-08-12 15:44:36.653241: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2019-08-12 15:44:36.653261: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2019-08-12 15:44:36.653280: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2019-08-12 15:44:36.653298: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2019-08-12 15:44:36.653316: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2019-08-12 15:44:36.653336: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2019-08-12 15:44:36.653478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:36.654061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:36.654476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2019-08-12 15:44:36.654525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-08-12 15:44:36.654541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2019-08-12 15:44:36.654553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2019-08-12 15:44:36.654896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:36.655330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-08-12 15:44:36.655664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12179 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","W0812 15:44:37.096362 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:288: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","W0812 15:44:37.097045 139670263756672 deprecation.py:323] From /content/models/research/object_detection/exporter.py:291: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0812 15:44:37.097887 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:297: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","W0812 15:44:37.098113 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:300: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","W0812 15:44:37.098408 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:305: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","W0812 15:44:37.098722 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/exporter.py:307: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n","\n","I0812 15:44:37.099165 139670263756672 builder_impl.py:636] No assets to save.\n","I0812 15:44:37.099286 139670263756672 builder_impl.py:456] No assets to write.\n","I0812 15:44:37.406108 139670263756672 builder_impl.py:421] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n","W0812 15:44:37.436827 139670263756672 deprecation_wrapper.py:119] From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","I0812 15:44:37.437062 139670263756672 config_util.py:190] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"usgBZvkz0nqD","colab_type":"code","outputId":"c6e2f0d7-3f81-4565-d233-2eb3811a8a48","executionInfo":{"status":"ok","timestamp":1565624685024,"user_tz":-330,"elapsed":3093,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":97}},"source":["!ls {output_directory}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["checkpoint\t\t\tmodel.ckpt.index  saved_model\n","frozen_inference_graph.pb\tmodel.ckpt.meta\n","model.ckpt.data-00000-of-00001\tpipeline.config\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p09AOThWkaQv","colab_type":"text"},"source":["## Download the model `.pb` file"]},{"cell_type":"code","metadata":{"id":"CnDo1lonKgFr","colab_type":"code","colab":{}},"source":["import os\n","\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHqWkLBINYoI","colab_type":"code","outputId":"b1a20b68-7ac2-4d39-b7f5-9b0382bd2cf6","executionInfo":{"status":"ok","timestamp":1565624691432,"user_tz":-330,"elapsed":3056,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["!ls -alh {pb_fname}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["-rw-r--r-- 1 root root 19M Aug 12 15:44 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FIqnjbWYsuQw","colab_type":"text"},"source":["### Option1 : upload the `.pb` file to your Google Drive\n","Then download it from your Google Drive to local file system.\n","\n","During this step, you will be prompted to enter the token."]},{"cell_type":"code","metadata":{"id":"hAqyASIJqjae","colab_type":"code","outputId":"64dce001-25d8-4cdc-b389-84ecdcb23e3f","executionInfo":{"status":"ok","timestamp":1565624720782,"user_tz":-330,"elapsed":26195,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":544}},"source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","fname = os.path.basename(pb_fname)\n","# Create & upload a text file.\n","uploaded = drive.CreateFile({'title': fname})\n","uploaded.SetContentFile(pb_fname)\n","uploaded.Upload()\n","print('Uploaded file with ID {}'.format(uploaded.get('id')))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |▎                               | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 850kB/s eta 0:00:02\r\u001b[K     |█                               | 30kB 1.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 835kB/s eta 0:00:02\r\u001b[K     |█▋                              | 51kB 1.0MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 1.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 1.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 1.6MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 1.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 1.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 1.4MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 1.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 1.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 1.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 1.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 1.4MB/s \n","\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"},{"output_type":"stream","text":["W0812 15:45:18.498561 139684626577280 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n","    from google.appengine.api import memcache\n","ModuleNotFoundError: No module named 'google.appengine'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n","    from oauth2client.contrib.locked_file import LockedFile\n","ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n","    from oauth2client.locked_file import LockedFile\n","ModuleNotFoundError: No module named 'oauth2client.locked_file'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n","    from . import file_cache\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n","    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n","ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"],"name":"stderr"},{"output_type":"stream","text":["Uploaded file with ID 1aIC7ePavU70vv-l_wezFdhGd7PnOHWkS\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2FKFq8RXs6bs","colab_type":"text"},"source":["### Option2 :  Download the `.pb` file directly to your local file system\n","This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."]},{"cell_type":"code","metadata":{"id":"-bP0iMMnnr77","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download(pb_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MFyCeiBb9BbS","colab_type":"text"},"source":["### Download the `label_map.pbtxt` file"]},{"cell_type":"code","metadata":{"id":"K1TbL6Ox8q6Z","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download(label_map_pbtxt_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUmAo9foa1xq","colab_type":"text"},"source":["### Download the modified pipline file\n","If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"]},{"cell_type":"code","metadata":{"id":"pql2QpemazE1","colab_type":"code","colab":{}},"source":["files.download(pipeline_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1AgBj1l0v_W","colab_type":"code","colab":{}},"source":["# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n","# from google.colab import files\n","# files.download('fine_tuned_model.tar.gz')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mz1gX19GlVW7","colab_type":"text"},"source":["## Run inference test\n","Test with images in repository `object_detection_demo/test` directory."]},{"cell_type":"code","metadata":{"id":"Pzj9A4e5mj5l","colab_type":"code","outputId":"fbfbd6a2-ea01-437a-b840-9375fc063385","executionInfo":{"status":"ok","timestamp":1565624863165,"user_tz":-330,"elapsed":1192,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":74}},"source":["import os\n","import glob\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = project_path + 'fine_tuned_model/frozen_inference_graph.pb'\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = project_path + 'fine_tuned_model/label_map.pbtxt'\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n","\n","assert os.path.isfile(PATH_TO_CKPT)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['/content/object_detection_demo/test/000070.jpeg', '/content/object_detection_demo/test/000039.jpg', '/content/object_detection_demo/test/000032.jpg', '/content/object_detection_demo/test/000036.jpg', '/content/object_detection_demo/test/000035.jpg', '/content/object_detection_demo/test/000010.jpg', '/content/object_detection_demo/test/000003.jpg', '/content/object_detection_demo/test/000044.jpg', '/content/object_detection_demo/test/000021.jpg', '/content/object_detection_demo/test/000018.jpg', '/content/object_detection_demo/test/000004.jpeg', '/content/object_detection_demo/test/000011.jpg', '/content/object_detection_demo/test/000016.jpg', '/content/object_detection_demo/test/000026.jpg', '/content/object_detection_demo/test/000063.jpeg', '/content/object_detection_demo/test/000054.jpg', '/content/object_detection_demo/test/000005.jpg', '/content/object_detection_demo/test/000019-2.jpg', '/content/object_detection_demo/test/000-0.jpg', '/content/object_detection_demo/test/000067.jpeg', '/content/object_detection_demo/test/000007.jpg', '/content/object_detection_demo/test/000040-2.jpg', '/content/object_detection_demo/test/000004-2.jpg', '/content/object_detection_demo/test/000019.jpeg', '/content/object_detection_demo/test/000017.jpg', '/content/object_detection_demo/test/000040.jpeg', '/content/object_detection_demo/test/000022.jpg', '/content/object_detection_demo/test/000025.jpg', '/content/object_detection_demo/test/000015.jpg', '/content/object_detection_demo/test/000020.jpg', '/content/object_detection_demo/test/000030.jpg', '/content/object_detection_demo/test/000073.jpg', '/content/object_detection_demo/test/000069.jpeg', '/content/object_detection_demo/test/000065.jpg']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CG5YUMdg1Po7","colab_type":"code","outputId":"13b1344d-1421-44d3-af7c-6fd252166299","executionInfo":{"status":"ok","timestamp":1565624923681,"user_tz":-330,"elapsed":49418,"user":{"displayName":"Siddharth Mehta","photoUrl":"","userId":"08582161435967967996"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1yK7zs3lH07UaVlzAncedrEOTFA0ZBA8l"}},"source":["%cd /content/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util\n","\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"GStNeHWPkTcN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}